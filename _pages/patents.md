---
permalink: /SHUTS/
title: "SHUTS Multi-Modal Lab"
author_profile: true
---



> _Chivalrous hunters, chasing SOTAs._

<div align="center">
<img src="https://github.com/SHUTS-MM-LAB/.github/blob/main/profile/pics/SHUTS_LOGO.png?raw=true" alt="fail" width="30%">
</div> 

<div align="center">
<img src='https://img.shields.io/badge/CVPR 2025-3 papers-brightgreen.svg' /> <img src='https://img.shields.io/badge/ICME 2025-1 paper-blue.svg' />
</div>

<br>

**S**ota-**HU**n**T**er**S** (SHUTS) Lab is an open research group founded by members from **Shanghai University** (SHU) and **the University of Technology Sydney** (UTS), dedicated to multi-modal learning and any other compelling areas of AI research. 

SHUTS Lab welcomes AI enthusiasts from all around the world to join in the pursuit of state-of-the-art advancements.



## Homepage

<table style="width: 50%; min-width: 200px;">
  <tr>
    <td valign="top" style="padding: 12px; border: 1px solid #ddd; border-radius: 8px;">
      <a href="https://github.com/SHUTS-MM-LAB" target="_blank" style="text-decoration: none; font-weight: bold; font-size: 16px; color: #6e40c9;">
        ğŸ–¥ï¸ SHUTS Multi-Modal Lab
      </a>
      <br>
      <span style="font-size: 13px; color: #555;">
        Sota-HUnTerS :: ShangHai University - University of Technology Sydney Joint Multimodal Research Group
      </span>
    </td>
  </tr>
</table>


## Members

| People                                                       | Introduction                                                 |
| ------------------------------------------------------------ | ------------------------------------------------------------ |
| <img src="https://avatars.githubusercontent.com/u/187282703?v=4" style="width:120px"><br><center><a href="https://github.com/JREion/cv">HaoyangÂ Li</a></center> | Joint Ph.D. student at the University of Technology Sydney (UTS) and Shanghai University (SHU), and founding member of the SHUTS Multi-modal Lab. His primary research focuses on parameter-efficient fine-tuning of pre-trained vision-language models. <br>æ‚‰å°¼ç§‘æŠ€å¤§å­¦ & ä¸Šæµ·å¤§å­¦è”åˆåŸ¹å…»åšå£«ç”Ÿï¼ŒSHUTS MM-Lab åˆ›å§‹äººã€‚ä¸»è¦ç ”ç©¶æ–¹å‘ä¸ºè§†è§‰-è¯­è¨€æ¨¡å‹çš„å‚æ•°é«˜æ•ˆå¾®è°ƒã€‚ |
| <img src="https://avatars.githubusercontent.com/u/58732931?v=4" style="width:120px"><br><center><a href="https://scholar.google.com/citations?user=mTEmqvUAAAAJ">LiangÂ Wang</a></center> | Joint Ph.D. student at the University of Technology Sydney (UTS) and Shanghai University (SHU). His primary research focuses on parameter-efficient fine-tuning of pre-trained vision-language models.<br>æ‚‰å°¼ç§‘æŠ€å¤§å­¦ & ä¸Šæµ·å¤§å­¦è”åˆåŸ¹å…»åšå£«ç”Ÿã€‚ä¸»è¦ç ”ç©¶æ–¹å‘ä¸ºè§†è§‰-è¯­è¨€æ¨¡å‹çš„å‚æ•°é«˜æ•ˆå¾®è°ƒã€‚ |
| <img src="https://avatars.githubusercontent.com/u/109060173?v=4" style="width:120px"><br/><center><a href="https://github.com/Apple-jun">QileÂ He</a></center> | A master student at Shanghai University (SHU), engaged in the research of music generation. <br>ä¸Šæµ·å¤§å­¦ç¡•å£«ç”Ÿã€‚ä¸»è¦ç ”ç©¶æ–¹å‘ä¸ºéŸ³ä¹ç”Ÿæˆã€‚ |
| <img src="https://avatars.githubusercontent.com/u/71584437?v=4" style="width:120px"><br><center><a href="https://scholar.google.com/citations?user=y5Lu4UUAAAAJ">SiyuÂ Zhou</a></center> | A Ph.D. student at the University of Technology Sydney (UTS), with primary research interests in embodied agents based on Large Language Models (LLMs) and reinforcement learning.  <br>æ‚‰å°¼ç§‘æŠ€å¤§å­¦åšå£«ç”Ÿã€‚ä¸»è¦ç ”ç©¶æ–¹å‘ä¸ºåŸºäº LLMs çš„å…·èº«ä»£ç†ã€å¼ºåŒ–å­¦ä¹ ã€‚ |
| <img src="https://avatars.githubusercontent.com/u/73231802?v=4" style="width:120px"><br/><center><a href="https://github.com/Sun15194">JiachengÂ Sun</a></center> | Ph.D. student at Shanghai University (SHU), with primary research interests in 2D/3D instance segmentation.<br>ä¸Šæµ·å¤§å­¦åšå£«ç”Ÿã€‚ä¸»è¦ç ”ç©¶æ–¹å‘ä¸º 2D/3D å®ä¾‹åˆ†å‰²ã€‚ |



