---
permalink: /SHUTS/
title: "SHUTS Multi-Modal Lab"
author_profile: true
---



> _Chivalrous hunters, chasing SOTAs._

<div align="center">
<img src="https://github.com/SHUTS-MM-LAB/.github/blob/main/profile/pics/SHUTS_LOGO.png?raw=true" alt="fail" width="30%">
</div> 

<div align="center">
<img src='https://img.shields.io/badge/CVPR 2025-3 papers-brightgreen.svg' /> <img src='https://img.shields.io/badge/ICME 2025-1 paper-blue.svg' />
</div>

<br>

**S**ota-**HU**n**T**er**S** (SHUTS) Lab is an open research group founded by members from **Shanghai University** (SHU) and **the University of Technology Sydney** (UTS), dedicated to multi-modal learning and any other compelling areas of AI research. 

SHUTS Lab welcomes AI enthusiasts from all around the world to join in the pursuit of state-of-the-art advancements.



## Homepage

<table style="width: 50%; min-width: 200px;">
  <tr>
    <td valign="top" style="padding: 12px; border: 1px solid #ddd; border-radius: 8px;">
      <a href="https://github.com/SHUTS-MM-LAB" target="_blank" style="text-decoration: none; font-weight: bold; font-size: 16px; color: #6e40c9;">
        🖥️ SHUTS Multi-Modal Lab
      </a>
      <br>
      <span style="font-size: 13px; color: #555;">
        Sota-HUnTerS :: ShangHai University - University of Technology Sydney Joint Multimodal Research Group
      </span>
    </td>
  </tr>
</table>


## Members

| People                                                       | Introduction                                                 |
| ------------------------------------------------------------ | ------------------------------------------------------------ |
| <img src="https://avatars.githubusercontent.com/u/187282703?v=4" style="width:120px"><br><center><a href="https://github.com/JREion/cv">Haoyang Li</a></center> | Joint Ph.D. student at the University of Technology Sydney (UTS) and Shanghai University (SHU), and founding member of the SHUTS Multi-modal Lab. His primary research focuses on parameter-efficient fine-tuning of pre-trained vision-language models. <br>悉尼科技大学 & 上海大学联合培养博士生，SHUTS MM-Lab 创始人。主要研究方向为视觉-语言模型的参数高效微调。 |
| <img src="https://avatars.githubusercontent.com/u/58732931?v=4" style="width:120px"><br><center><a href="https://scholar.google.com/citations?user=mTEmqvUAAAAJ">Liang Wang</a></center> | Joint Ph.D. student at the University of Technology Sydney (UTS) and Shanghai University (SHU). His primary research focuses on parameter-efficient fine-tuning of pre-trained vision-language models.<br>悉尼科技大学 & 上海大学联合培养博士生。主要研究方向为视觉-语言模型的参数高效微调。 |
| <img src="https://avatars.githubusercontent.com/u/109060173?v=4" style="width:120px"><br/><center><a href="https://github.com/Apple-jun">Qile He</a></center> | A master student at Shanghai University (SHU), engaged in the research of music generation. <br>上海大学硕士生。主要研究方向为音乐生成。 |
| <img src="https://avatars.githubusercontent.com/u/71584437?v=4" style="width:120px"><br><center><a href="https://scholar.google.com/citations?user=y5Lu4UUAAAAJ">Siyu Zhou</a></center> | A Ph.D. student at the University of Technology Sydney (UTS), with primary research interests in embodied agents based on Large Language Models (LLMs) and reinforcement learning.  <br>悉尼科技大学博士生。主要研究方向为基于 LLMs 的具身代理、强化学习。 |
| <img src="https://avatars.githubusercontent.com/u/73231802?v=4" style="width:120px"><br/><center><a href="https://github.com/Sun15194">Jiacheng Sun</a></center> | Ph.D. student at Shanghai University (SHU), with primary research interests in 2D/3D instance segmentation.<br>上海大学博士生。主要研究方向为 2D/3D 实例分割。 |



